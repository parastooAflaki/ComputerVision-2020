{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Increase_RAM_Reference_Notes_By_Techhawa_ (4).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBRbC3FNIJtr"
      },
      "source": [
        "from google.colab import drive\n",
        " \n",
        "# Accessing My Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkzg-0OgI2VL"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgIJJ6piJC41"
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"mahtab99\",\"key\":\"f7c082e582d76ad23f429ca74c08bf3d\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnZDIXQNJJIB"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM3NYVkaJU6h"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plaTlqNJECVh"
      },
      "source": [
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge -p /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BfJ8a5bJ0Kh"
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87T5BetZQYQv"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.random.set_seed(1234)\n",
        "!pip3 install tensorflow-datasets==1.2.0\n",
        "import tensorflow_datasets as tfds\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout ,Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "9iq_7e---ip_"
      },
      "source": [
        "data_set = pd.read_csv('train.csv')\n",
        "test_set = pd.read_csv('test.csv')\n",
        "data = pd.read_csv('icml_face_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "agnsWGf4-iqB"
      },
      "source": [
        "data_set.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L76BSSGyguEX"
      },
      "source": [
        "data_set.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ibnTifyZ-iqC"
      },
      "source": [
        "import collections\n",
        "ax = np.array(data_set.emotion)\n",
        "collections.Counter(ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etoedkyjkvN4"
      },
      "source": [
        "len (data_set[\"pixels\"][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_9b6AOHKvTt"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd8Ni0b1c0P9"
      },
      "source": [
        "# Display two images\n",
        "def display(a, b, title1 = \"Original\", title2 = \"Edited\"):\n",
        "    plt.subplot(121), plt.imshow(a), plt.title(title1)\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(122), plt.imshow(b), plt.title(title2)\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5RxWsaC3-iqD"
      },
      "source": [
        "def data_prep(data):\n",
        "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
        "    image_label = np.array(list(map(int, data['emotion'])))\n",
        "    for i, row in enumerate(data.index):\n",
        "        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n",
        "        image = np.reshape(image, (48, 48))\n",
        "        if i==11:\n",
        "          original_image = image\n",
        "          img = image \n",
        "        image = cv2.normalize(image.astype(np.uint8),  None , 0, 255, cv2.NORM_MINMAX)\n",
        "        image = cv2.equalizeHist(image.astype(np.uint8))\n",
        "        image_array[i] = image\n",
        "        if i==11:\n",
        "          norm_img = image\n",
        "          image = median_filter(np.float32(img), 5 )\n",
        "          noise_removed_image = image\n",
        "          img =  img.astype(np.uint8)\n",
        "          edge_image = cv2.Canny(img,150,200)\n",
        "    display(original_image,norm_img,\"original\",\"normalize & equalize\") \n",
        "    display(original_image,noise_removed_image,\"original\",\"removed noise\")    \n",
        "    display(original_image,edge_image,\"original\",\"Edges\")    \n",
        "    return image_array, image_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt9W2C8eKfwm"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def median_filter(img, filter_size):\n",
        "    temp = []\n",
        "    index = filter_size // 2\n",
        "    new_img = []\n",
        "    new_img = np.zeros((img.shape[0], img.shape[1]), np.int32)\n",
        "    for i in (range(img.shape[0])):\n",
        "        for j in (range(img.shape[1])):\n",
        "            if img[i][j]== 0 or img[i][j] == 255 :\n",
        "              coun=0\n",
        "              for z in range(filter_size):\n",
        "                if -1<i + z - index < img.shape[0]:   \n",
        "                    for k in range(filter_size):\n",
        "                      if(-1<j + k - index<img.shape[1]):\n",
        "                          temp.append(img[i + z - index][j + k - index])\n",
        "              temp.sort()\n",
        "              new_img[i][j] = temp[int(len(temp) / 2)]\n",
        "              temp = []\n",
        "            else:\n",
        "              new_img[i][j]= img[i][j]\n",
        "    plt.imshow(new_img, cmap=plt.get_cmap('gray'))\n",
        "    plt.plot()\n",
        "    return new_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0nNvkMg_-iqE"
      },
      "source": [
        "X , Y = data_prep(data_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8wSB7O8CaA3F"
      },
      "source": [
        "def split_data(X,Y):  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=41)\n",
        "  X_train = X_train.reshape((X_train.shape[0], 48, 48, 1))\n",
        "  X_train = X_train.astype('float32')/255\n",
        "  X_valid = X_valid.reshape((X_valid.shape[0], 48, 48, 1))\n",
        "  X_valid = X_valid.astype('float32')/255\n",
        "  X_test = X_test.reshape((X_test.shape[0], 48, 48, 1))\n",
        "  X_test = X_test.astype('float32')/255\n",
        "  y_train = keras.utils.to_categorical(y_train)\n",
        "  y_valid = keras.utils.to_categorical(y_valid)\n",
        "  y_test = keras.utils.to_categorical(y_test)\n",
        "  print (\"X_train shape: \" + str(X_train.shape))\n",
        "  print (\"Y_train shape: \" + str(y_train.shape))\n",
        "  print (\"X_test shape: \" + str(X_test.shape))\n",
        "  print (\"Y_test shape: \" + str(y_test.shape))\n",
        "  print (\"X_valid shape: \" + str(X_valid.shape))\n",
        "  print (\"Y_valid shape: \" + str(y_valid.shape))\n",
        "  return X_train, X_test, y_train, y_test ,X_valid, y_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kz9zIEl5aA3L"
      },
      "source": [
        "X_train, X_test, y_train, y_test, X_valid, y_valid  = split_data(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqNMMZAROPkf"
      },
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot \n",
        "def display_preprocessing(X_train):\n",
        "      for i in range(10000, 10009):\n",
        "          pyplot.subplot(330 + 1 + i-10000)\n",
        "          pyplot.imshow(X_train[i].reshape(48,48) ,cmap=plt.get_cmap('gray'))\n",
        "      # show the plot\n",
        "      pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtubSDd5YPdC"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(\"Original\")\n",
        "display_preprocessing(X_train)\n",
        "\n",
        "# normalization_datagen = ImageDataGenerator( featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
        "#         samplewise_std_normalization=True,  # divide each input by its std\n",
        "#         featurewise_center=True,  # set input mean to 0 over the dataset\n",
        "#         samplewise_center=True  # set each sample mean to 0\n",
        "# )\n",
        "# normalization_datagen.fit(X_train)\n",
        "# normalization_datagen.fit(X_valid)\n",
        "# print(\"Normalize\")\n",
        "# display_preprocessing(X_train)\n",
        "\n",
        "# rotation_range_datagen = ImageDataGenerator(rotation_range=10) \n",
        "# rotation_range_datagen.fit(X_train)\n",
        "# rotation_range_datagen.fit(X_valid)\n",
        "# print(\"Rotation\")\n",
        "# display_preprocessing(X_train)\n",
        "\n",
        "# zoom_range_datagen = ImageDataGenerator(zoom_range = 0.1)\n",
        "# zoom_range_datagen.fit(X_train)\n",
        "# zoom_range_datagen.fit(X_valid)\n",
        "# print(\"Zoom\")\n",
        "# display_preprocessing(X_train)\n",
        "\n",
        "# shift_datagen = ImageDataGenerator(width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "#         height_shift_range=0.1  # randomly shift images vertically (fraction of total height)\n",
        "# )\n",
        "# shift_datagen.fit(X_train)\n",
        "# shift_datagen.fit(X_valid)\n",
        "# print(\"Shift\")\n",
        "# display_preprocessing(X_train)\n",
        "\n",
        "# horizontal_flip_datagen =  ImageDataGenerator(horizontal_flip=True)\n",
        "# horizontal_flip_datagen.fit(X_train)\n",
        "# horizontal_flip_datagen.fit(X_valid)\n",
        "# print(\"Horizontal flip\")\n",
        "# display_preprocessing(X_train)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        # rescale = 1./255,\n",
        "        # zoom_range=[0.5,1.0],\n",
        "        brightness_range=[0.2,1.0],\n",
        "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=True,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=True,  # divide each input by its std\n",
        "        # zca_whitening=True,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range \n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "datagen.fit(X_train)\n",
        "datagen.fit(X_valid)\n",
        "display_preprocessing(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9K5yiiCo9yo"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCguFWd9RSSO"
      },
      "source": [
        "import pandas as pd\n",
        "def show_history(history):\n",
        "  pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY_aUwdZ7okx"
      },
      "source": [
        "## **paper model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tkbawdib-iqH"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "def generate_model(lr=0.001):\n",
        "    \n",
        "    \"\"\"training model\"\"\"\n",
        "    \n",
        "    with tf.device('/gpu:0'):  \n",
        "        \n",
        "        model = keras.models.Sequential()\n",
        "        \n",
        "        model.add(keras.layers.Conv2D(64,(3,3), input_shape=(48,48, 1), padding=\"same\"))\n",
        "        model.add(keras.layers.BatchNormalization())\n",
        "        model.add(keras.layers.Activation('relu'))\n",
        "        model.add(keras.layers.MaxPooling2D())\n",
        "        model.add(keras.layers.Dropout(0.20))\n",
        "        \n",
        "        model.add(keras.layers.Conv2D(128,(5,5), padding='same'))\n",
        "        model.add(keras.layers.BatchNormalization())\n",
        "        model.add(keras.layers.Activation('relu'))\n",
        "        model.add(keras.layers.MaxPooling2D())\n",
        "        model.add(keras.layers.Dropout(0.20))\n",
        "\n",
        "        model.add(keras.layers.Conv2D(512,(3,3), padding=\"same\"))\n",
        "        model.add(keras.layers.BatchNormalization())\n",
        "        model.add(keras.layers.Activation('relu'))\n",
        "        model.add(keras.layers.MaxPooling2D())\n",
        "        model.add(keras.layers.Dropout(0.20))\n",
        "        \n",
        "        model.add(keras.layers.Conv2D(512,(3,3)))\n",
        "        model.add(keras.layers.BatchNormalization())\n",
        "        model.add(keras.layers.Activation('relu'))\n",
        "        model.add(keras.layers.MaxPooling2D())\n",
        "        model.add(keras.layers.Dropout(0.25))\n",
        "        \n",
        "        model.add(keras.layers.Conv2D(256,(3,3), activation='relu',padding='same'))\n",
        "        model.add(keras.layers.Conv2D(128,(3,3), padding='same', activation='relu'))\n",
        "        model.add(keras.layers.MaxPooling2D())\n",
        "        model.add(keras.layers.Dropout(0.25))\n",
        "        \n",
        "        \n",
        "        model.add(keras.layers.Flatten())\n",
        "        model.add(keras.layers.Dense(256))\n",
        "        model.add(keras.layers.BatchNormalization())\n",
        "        model.add(keras.layers.Activation('relu'))\n",
        "        model.add(keras.layers.Dropout(0.5))\n",
        "        \n",
        "        model.add(keras.layers.Dense(512, activation='relu'))\n",
        "        model.add(keras.layers.BatchNormalization())\n",
        "        model.add(keras.layers.Activation('relu'))\n",
        "        model.add(keras.layers.Dropout(0.5))\n",
        "        \n",
        "        model.add(keras.layers.Dense(7,activation='softmax'))\n",
        "\n",
        "        opt = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "        loss = keras.losses.categorical_crossentropy\n",
        "        model.compile(loss = keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
        "        model.summary()\n",
        "        plot_model(model, to_file='fer_model.png', show_shapes=True, show_layer_names=True)\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mKTK6RoY-iqI"
      },
      "source": [
        "model = generate_model(0.01)\n",
        "tf.keras.utils.plot_model(\n",
        "    model, to_file='paper_model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vfMvGjZf-iqI"
      },
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CVision' + '/paper_model.h5',save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20,restore_best_weights=True)\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "learn_rate_fuc = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                   patience=3,\n",
        "                                   verbose=1,\n",
        "                                   factor=0.5,\n",
        "                                   min_lr=0.000005)\n",
        "with tf.device(\"/gpu:0\"):\n",
        "\n",
        "  history = model.fit(\n",
        "      X_train,y_train,\n",
        "      validation_data = (X_valid,y_valid), \n",
        "      verbose=1,\n",
        "      batch_size=128,\n",
        "      callbacks=[checkpoint_cb, early_stopping_cb,learn_rate_fuc],\n",
        "      epochs = 60)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hbTgudroSVT"
      },
      "source": [
        "show_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Nd-mCeEzhr"
      },
      "source": [
        "def test_prediction(model , X_test,y_test):\n",
        "  test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "  print('test caccuracy:', test_acc)\n",
        "  pred_test_labels = model.predict(X_test)\n",
        "  for i in range(100 ,110,2):\n",
        "    plot_image(X_test, y_test, pred_test_labels, i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVxLcHnKE9-v"
      },
      "source": [
        "def plot_image(X_test, y_test, pred_test_labels, image_number):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 6), sharey=False)\n",
        "    emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
        "    bar_label = emotions.values()\n",
        "\n",
        "    axs[0].imshow(X_test[image_number].reshape(48,48),cmap=plt.get_cmap('gray'))\n",
        "    title=0\n",
        "    for i in range (0,7):\n",
        "      if y_test[image_number][i] == 1 :\n",
        "        title=i\n",
        "    axs[0].set_title(emotions[title])\n",
        "    \n",
        "    axs[1].bar(bar_label, pred_test_labels[image_number], color='orange', alpha=0.7)\n",
        "    axs[1].grid()\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qm8PoPTFKEi"
      },
      "source": [
        "test_prediction(model , X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh7UAkp574dI"
      },
      "source": [
        "## mini VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCqGDzklVjj7"
      },
      "source": [
        "input_size=(48, 48, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cyjr-A2aPuo"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.python.keras import regularizers\n",
        "def model_vgg():\n",
        "        model = Sequential(name=\"MiniVGG13\")\n",
        "        model.add(Conv2D(64, (3, 3), input_shape=input_size, padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=1))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        model.add(Dropout(0.35))\n",
        "\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=1))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        model.add(Dropout(0.35))\n",
        "\n",
        "       \n",
        "        model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=1))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        model.add(Dropout(0.35))\n",
        "\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=1))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        model.add(Dropout(0.35))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=1))\n",
        "        model.add(Dropout(0.35))\n",
        "\n",
        " \n",
        "        model.add(Dense(64, kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=1))\n",
        "        model.add(Dropout(0.35))\n",
        "\n",
        "        \n",
        "        model.add(Dense(7, kernel_regularizer=regularizers.l2(0.0002)))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "\n",
        "        opt = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "        loss = keras.losses.categorical_crossentropy\n",
        "        model.compile(loss = keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
        "        model.summary()\n",
        "        plot_model(model, to_file='vgg_model.png', show_shapes=True, show_layer_names=True)\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEePi3Ucdmaf"
      },
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CVision' + '/vgg_model.h5',save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20,restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnnOVVE6drKL"
      },
      "source": [
        "model = model_vgg()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBCD1FH2dzkh"
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "learn_rate_fuc = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                   patience=3,\n",
        "                                   verbose=1,\n",
        "                                   factor=0.5,\n",
        "                                   min_lr=0.000005)\n",
        "history_vgg_model = model.fit(\n",
        "    X_train,y_train,\n",
        "    validation_data = (X_valid,y_valid), \n",
        "    verbose=1,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb,learn_rate_fuc],\n",
        "    epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLpluaeaRjRJ"
      },
      "source": [
        "show_history(history_vgg_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ClOmjowFUJJ"
      },
      "source": [
        "test_prediction(model , X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqbgpyfZ8A0x"
      },
      "source": [
        "### costum model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sybweiygiqck"
      },
      "source": [
        "def costum_model():\n",
        "  num_features=64\n",
        "  model = Sequential(name = 'costum-model')\n",
        "\n",
        "  model.add(Conv2D(num_features, kernel_size=(3, 3),padding=\"same\", activation='relu', input_shape=(48,48,1), kernel_regularizer=l2(0.01)))\n",
        "  model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(2*2*2*num_features, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(2*2*num_features, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(2*num_features, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "  loss = keras.losses.categorical_crossentropy\n",
        "  model.compile(loss = keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  plot_model(model, to_file='costum_model.png', show_shapes=True, show_layer_names=True)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_5Tr1OEjhy0"
      },
      "source": [
        "model = costum_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7XKGxzdjZCK"
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "learn_rate_fuc = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                   patience=3,\n",
        "                                   verbose=1,\n",
        "                                   factor=0.5,\n",
        "                                   min_lr=0.000005)\n",
        "\n",
        "history_costum_model = model.fit(\n",
        "    X_train,y_train,\n",
        "    validation_data = (X_valid,y_valid), \n",
        "    verbose=1,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb,learn_rate_fuc],\n",
        "    epochs = 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLkot9JkjvS9"
      },
      "source": [
        "show_history(history_costum_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CalSc0nZnux5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}